-- ds.page: `publish-static` S3 Interface

-- ds.h1: S3 Bucket `fastn-user-packages`

In S3, we have a bucket `fastn-user-packages`, where we are keeping all the
packages. In the docs we are going to refer to this as `$BUCKET`.

-- ds.h1: `$BUCKET/updated-packages.txt`

This file contains the name of the latest `$BUCKET/updated-packages-<ts>.txt`
file.

-- ds.h1: `$BUCKET/updated-packages-<ts>.txt`

On every successful upload of a package on `fastn-cw`, we will add one line to
this file.

-- ds.code: Content Of Each Entry
lang: txt

<cw-id>:<timestamp>

-- ds.markdown:

Every hour `fastn-cw` rotates this file by creating a new file matching
`$BUCKET/updated-packages-<ts>.txt` pattern. `fastn-cw` writes the name of new
file in the current `updated-packages-<ts>` file: `file-ended: <next-file>.txt`,
and in the `$BUCKET/updated-packages.txt` file.


-- ds.h1: `$BUCKET/<domain-name>.txt`

For each full-domain, eg domain=amitu.fastn-site.com or domain=amitu.com, we
will have `$BUCKET/amitu.fastn-site.com.txt` or `$BUCKET/amitu.com.txt`.

The content of this file would be the `cw-id` for that package.



-- ds.h1: `$BUCKET/<cw-id>/LIST.tejar-list`

In LIST.tejar-list we have all the files with its information like `size`,
`content-type`, `file-name`, `data-file-name` and `checksum` of the file content.
Whenever new upload comes to this `fastn-cw` for package, entries will appended
to this file.

-- ds.code:
lang: txt

$BUCKET/<cw-id>/DATA-<timestamp>.tejar-data|index.html|0|980427|text/html|none|1677654431|a0bbd23afd533396e5499a94f1b4c85fb4078e671f1f8f142dfdec8eb5b2e2e6

-- ds.markdown:

The fields are:

1. the name of tejar-data file where the content if the file is stored
2. the name of the file
3. the start location for the file in the tejar-data file
4. compressed size of the file (start till this size must be read from tejar-data)
5. size of the file
6. content type of the file
7. timestamp in nanoseconds.
8. `shasum -a 256` of the file


Note these fields matches with tejar::TejarRecord struct.

Note: this is an append only file, we never truncate it.


Note on compression: we always compress the file to brotli before storing.

If the browser does not support brotli but supports gzip we have decided to
incur the CPU hit for now.


-- ds.h1: `$BUCKET/<cw-id>/DATA-<timestamp>.tejar-data`

`DATA-<timestamp>.tejar-data` file contains binary data on each success upload.








-- end: ds.page
